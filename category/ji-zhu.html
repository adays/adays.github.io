<!DOCTYPE html>
<html lang="ch">
<head>
        <meta charset="utf-8" />
        <title>One Day - 技术</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="One Day Atom Feed" />

        <!--[if IE]>
            <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">One Day </a></h1>
                <nav><ul>
                    <li class="active"><a href="/category/ji-zhu.html">技术</a></li>
                    <li><a href="/category/ri-ji.html">日记</a></li>
                    <li><a href="/category/ri-zhi.html">日志</a></li>
                    <li><a href="/category/za-sui.html">杂碎</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="/ji-qi-xue-xi-de-ye-lu-zi.html">机器学习的野路子</a></h1>
<footer class="post-info">
        <abbr class="published" title="2014-08-19T00:00:00">
                 Tue 19 August 2014
        </abbr>
        <p>haoyuan.huhy@gmail.com</p>
<p> <a href="/category/ji-zhu.html">技术</a> </p>

</footer><!-- /.post-info --><h1>前言</h1>
<p>机器学习很大程度上归为三个步骤：</p>
<ol>
<li>问题定义</li>
<li>数据准备</li>
<li>特征工程</li>
</ol>
<p>在漫漫长河中， 各路人士留下个各种民间智慧。</p>
<h1>ABE：永远在融合</h1>
<p>不管怎么样， ensembleing， 免费的午餐。</p>
<h1>高置信度下才自动允许或者自动禁止</h1>
<h1>Feature Hash</h1>
<p>将高纬度的特征利用hash函数映射到低纬度的特征。</p>
<h1>样本严重不均衡</h1>
<p>将分类问题换成rank问题。</p>
<h1>一坨坨的分类器</h1>
<ul>
<li>bad， good</li>
<li>bad a， bad b</li>
</ul>
<h1>性能瓶颈</h1>
<p>十有八九在特征提取</p>
<h1>指标监控</h1>
<ul>
<li>准确率， 召回率</li>
<li>输入的特征分布</li>
<li>输出的得分分布</li>
<li>输出的分类结果分布</li>
<li>人工介入</li>
</ul>
<h1>专家智慧</h1>
<p>有时候允许砖家来拍规则， 前提的确是砖家</p>                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="/zao-yin-shu-ju-de-chu-li.html" rel="bookmark"
                           title="Permalink to 噪音数据的处理">噪音数据的处理</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2014-08-19T00:00:00">
                 Tue 19 August 2014
        </abbr>
        <p>haoyuan.huhy@gmail.com</p>
<p> <a href="/category/ji-zhu.html">技术</a> </p>

</footer><!-- /.post-info -->                <p>最近在追踪模型的时候， 发现了一系列比较严重的数据污染， 有些来自于采集过程， 有些则是spam， 顺手整理了一下噪音处理的相关tips。</p>
<h1>大数据中的预处理</h1>
<h1>步骤</h1>
<ul>
<li>数据清洗</li>
<li>数据集成</li>
<li>数据转换</li>
<li>数据降维</li>
</ul>
<h1>WHY</h1>
<ul>
<li>大数据带来的问题是， 海量的脏数据<ul>
<li>缺失：缺少某种类型的数据， 缺少部分样本的数据</li>
<li>噪音：数据收集过程中导致的错误或者越界</li>
<li>矛盾：数据之间互相矛盾</li>
</ul>
</li>
<li>没有高质量的数据， 就没有高质量的数据挖掘结果<ul>
<li>决策依赖于高质量的数据</li>
<li>模型依赖于高质量的数据</li>
</ul>
</li>
</ul>
<h1>measure</h1>
<ul>
<li>准确度</li>
<li>完整度</li>
<li>一致性</li>
<li>时间轴</li>
<li>可信度</li>
<li>附加值</li>
<li>可解释性</li>
<li>可获得性</li>
</ul>
<h1>main mission</h1>
<ul>
<li>数据清洗: 缺失值填充， 噪音平滑， 异常值处理</li>
<li>数据集成: 多种来源数据集成</li>
<li>数据转换: 标准化</li>
<li>数据降维: 合并相似数据   </li>
</ul>
<h1>data clean</h1>
<h3>数据清洗步骤</h3>
<ul>
<li>缺失值填充 ...</li></ul>
                <a class="readmore" href="/zao-yin-shu-ju-de-chu-li.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/shi-yong-pelicanda-jian-bo-ke.html" rel="bookmark"
                           title="Permalink to 使用pelican搭建博客">使用pelican搭建博客</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2014-08-18T00:00:00">
                 Mon 18 August 2014
        </abbr>
        <p>haoyuan.huhy@gmail.com</p>
<p> <a href="/category/ji-zhu.html">技术</a> </p>

</footer><!-- /.post-info -->                <p>之前的博客用的是octopress， 挺好的， 也没啥毛病， 就是我不会ruby，出个小问题纠结大半天。</p>
<p>因为最熟悉的语言是python，找了下有没有python的frame，发现还真有： pelican。</p>
<p>这下子就简单了：</p>
<ol>
<li>pip install pelican</li>
<li>pip install Markdown</li>
<li>pelican-quickstart</li>
</ol>
<p>这些整完后就可以写blog了。</p>
<p>很多人一上手就用了octopress， 反而弄混了，这里解释下：</p>
<ul>
<li><s>github pages, 在gh-pages下都是html文件。</s></li>
<li>octopress、pelican、jeklly， 都是用来生成这些html的。</li>
<li>理论上， 鉴于国内github的速度， 最好的办法是自己弄一台服务器，开一个最简单的http server。</li>
</ul>
<p>为了方便起见， 改写了MakeFile文件， 增加了对百度云的支持， 同时因为一部分文档是不适合泄露的，额外建立一个private的content和output的文件夹， 在MakeFile的html和serve那里增加了对这些的支持。</p>
<p>申请了一台阿里云的服务器， 准备部署。</p>
<h2>update</h2>
<p>申请到阿里云的服务器了， 在服务器上用了个最简单的httpserver:</p>
<div class="highlight"><pre><span class="n">nohup</span> <span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">SimpleHTTPServer</span> <span class="mi">80</span> <span class="o">&amp;</span>
</pre></div>
<p>在makefile里面配置rsync同步 ...</p>
                <a class="readmore" href="/shi-yong-pelicanda-jian-bo-ke.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/online learning.html" rel="bookmark"
                           title="Permalink to 实时策略">实时策略</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2013-12-18T00:00:00">
                 Wed 18 December 2013
        </abbr>
        <p>haoyuan.huhy@gmail.com</p>
<p> <a href="/category/ji-zhu.html">技术</a> </p>

</footer><!-- /.post-info -->                <p>传统的推荐以离线为主， 以预测用户偏好品牌为例，大致分为这几个步骤:</p>
<ul>
<li>离线采集计算用户， 品牌等各个维度的特征。</li>
<li>根据业务目标给出样本集合， 比如比较典型的CTR， 对于给定样本数据， 点击为正例， 不点击为负例。候选集的挑选有时候充满了trick， 尤其在业务的主体流量不是推荐的时候。</li>
<li>使用模型进行离线训练， 以线性模型居多， 包括LR, pair-wise, list-wise等。在海量情况下， 复杂模型比较罕见。</li>
<li>根据模型预测获得用户的偏好品牌列表。</li>
</ul>
<p>相对于直接利用热门或者协同过滤做出的推荐， 这种方式能够获得良好的提升以及更好的泛化能力， 但是面对以下几种情况无能为力：</p>
<ul>
<li>每天有大量新用户拥入。</li>
<li>用户对品牌的点击在过去没有特征， 看起来似乎是天外飞仙般出现， 但又不是热销。 </li>
<li>无法实时的对用户的正反馈和负反馈进行算法上的回馈， 尤其是当你发现你X掉了一堆东西， 类似的商品还在源源不断的涌向你的时候。</li>
</ul>
<p>实时的数据对于推荐系统而言， 是一座新的金矿， 可以为用户进行更准确地推荐， 同时及时响应各种反馈， 提升用户体验。 用户能感受到推荐系统和他的交互， 会更主动积极的贡献自己的行为特点， 从而形成良性循环。</p>
<p>比较常见的一种做法是实时特征的引入， 训练过程依然在离线完成：</p>
<ol>
<li>收集实时数据， 做离线训练</li>
<li>做在线预测</li>
</ol>
<p>另一部分采用的是online learning, 利用用户不停的行为反馈（包含显式的和隐式的）， 来调整特征权重。</p>
<p>现在在考虑一种在线增强学习的方式， 假定我们现在有四种投放策略 ...</p>
                <a class="readmore" href="/online learning.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>
                </ol><!-- /#posts-list -->
<p class="paginator">
    Page 1 / 1
</p>
                </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">

        </footer><!-- /#contentinfo -->

</body>
</html>