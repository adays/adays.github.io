<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>One Day</title><link href="/" rel="alternate"></link><link href="/feeds/ji-zhu.atom.xml" rel="self"></link><id>/</id><updated>2014-08-19T00:00:00+08:00</updated><entry><title>机器学习的野路子</title><link href="/ji-qi-xue-xi-de-ye-lu-zi.html" rel="alternate"></link><updated>2014-08-19T00:00:00+08:00</updated><author><name>haoyuan.huhy@gmail.com</name></author><id>tag:,2014-08-19:ji-qi-xue-xi-de-ye-lu-zi.html</id><summary type="html">&lt;h1&gt;前言&lt;/h1&gt;
&lt;p&gt;机器学习很大程度上归为三个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;问题定义&lt;/li&gt;
&lt;li&gt;数据准备&lt;/li&gt;
&lt;li&gt;特征工程&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在漫漫长河中， 各路人士留下个各种民间智慧。&lt;/p&gt;
&lt;h1&gt;ABE：永远在融合&lt;/h1&gt;
&lt;p&gt;不管怎么样， ensembleing， 免费的午餐。&lt;/p&gt;
&lt;h1&gt;高置信度下才自动允许或者自动禁止&lt;/h1&gt;
&lt;h1&gt;Feature Hash&lt;/h1&gt;
&lt;p&gt;将高纬度的特征利用hash函数映射到低纬度的特征。&lt;/p&gt;
&lt;h1&gt;样本严重不均衡&lt;/h1&gt;
&lt;p&gt;将分类问题换成rank问题。&lt;/p&gt;
&lt;h1&gt;一坨坨的分类器&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;bad， good&lt;/li&gt;
&lt;li&gt;bad a， bad b&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;性能瓶颈&lt;/h1&gt;
&lt;p&gt;十有八九在特征提取&lt;/p&gt;
&lt;h1&gt;指标监控&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;准确率， 召回率&lt;/li&gt;
&lt;li&gt;输入的特征分布&lt;/li&gt;
&lt;li&gt;输出的得分分布&lt;/li&gt;
&lt;li&gt;输出的分类结果分布&lt;/li&gt;
&lt;li&gt;人工介入&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;专家智慧&lt;/h1&gt;
&lt;p&gt;有时候允许砖家来拍规则， 前提的确是砖家&lt;/p&gt;</summary></entry><entry><title>噪音数据的处理</title><link href="/zao-yin-shu-ju-de-chu-li.html" rel="alternate"></link><updated>2014-08-19T00:00:00+08:00</updated><author><name>haoyuan.huhy@gmail.com</name></author><id>tag:,2014-08-19:zao-yin-shu-ju-de-chu-li.html</id><summary type="html">&lt;p&gt;最近在追踪模型的时候， 发现了一系列比较严重的数据污染， 有些来自于采集过程， 有些则是spam， 顺手整理了一下噪音处理的相关tips。&lt;/p&gt;
&lt;h1&gt;大数据中的预处理&lt;/h1&gt;
&lt;h1&gt;步骤&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;数据清洗&lt;/li&gt;
&lt;li&gt;数据集成&lt;/li&gt;
&lt;li&gt;数据转换&lt;/li&gt;
&lt;li&gt;数据降维&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;WHY&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;大数据带来的问题是， 海量的脏数据&lt;ul&gt;
&lt;li&gt;缺失：缺少某种类型的数据， 缺少部分样本的数据&lt;/li&gt;
&lt;li&gt;噪音：数据收集过程中导致的错误或者越界&lt;/li&gt;
&lt;li&gt;矛盾：数据之间互相矛盾&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;没有高质量的数据， 就没有高质量的数据挖掘结果&lt;ul&gt;
&lt;li&gt;决策依赖于高质量的数据&lt;/li&gt;
&lt;li&gt;模型依赖于高质量的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;measure&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;准确度&lt;/li&gt;
&lt;li&gt;完整度&lt;/li&gt;
&lt;li&gt;一致性&lt;/li&gt;
&lt;li&gt;时间轴&lt;/li&gt;
&lt;li&gt;可信度&lt;/li&gt;
&lt;li&gt;附加值&lt;/li&gt;
&lt;li&gt;可解释性&lt;/li&gt;
&lt;li&gt;可获得性&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;main mission&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;数据清洗: 缺失值填充， 噪音平滑， 异常值处理&lt;/li&gt;
&lt;li&gt;数据集成: 多种来源数据集成&lt;/li&gt;
&lt;li&gt;数据转换: 标准化&lt;/li&gt;
&lt;li&gt;数据降维: 合并相似数据   &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;data clean&lt;/h1&gt;
&lt;h3&gt;数据清洗步骤&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;缺失值填充&lt;/li&gt;
&lt;li&gt;越界值界定&lt;/li&gt;
&lt;li&gt;噪音平滑&lt;/li&gt;
&lt;li&gt;不一致数据纠正 &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;缺失值&lt;/h1&gt;
&lt;p&gt;说的什么&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;忽略缺失值， 尤其在部分分类情况下&lt;/li&gt;
&lt;li&gt;手动添加&lt;/li&gt;
&lt;li&gt;常数值替换&lt;/li&gt;
&lt;li&gt;均值替换&lt;/li&gt;
&lt;li&gt;分类均值替换&lt;/li&gt;
&lt;li&gt;最可能值替换：利用贝叶斯或者决策树&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;噪音数据&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;噪音:随机错误&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;错误值产生原因&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集过程&lt;/li&gt;
&lt;li&gt;输入过程&lt;/li&gt;
&lt;li&gt;数据转化过程&lt;/li&gt;
&lt;li&gt;命名不一致&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其余数据问题 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;重复记录&lt;/li&gt;
&lt;li&gt;不完整数据&lt;/li&gt;
&lt;li&gt;不一致数据&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>使用pelican搭建博客</title><link href="/shi-yong-pelicanda-jian-bo-ke.html" rel="alternate"></link><updated>2014-08-18T00:00:00+08:00</updated><author><name>haoyuan.huhy@gmail.com</name></author><id>tag:,2014-08-18:shi-yong-pelicanda-jian-bo-ke.html</id><summary type="html">&lt;p&gt;之前的博客用的是octopress， 挺好的， 也没啥毛病， 就是我不会ruby，出个小问题纠结大半天。&lt;/p&gt;
&lt;p&gt;因为最熟悉的语言是python，找了下有没有python的frame，发现还真有： pelican。&lt;/p&gt;
&lt;p&gt;这下子就简单了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pip install pelican&lt;/li&gt;
&lt;li&gt;pip install Markdown&lt;/li&gt;
&lt;li&gt;pelican-quickstart&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些整完后就可以写blog了。&lt;/p&gt;
&lt;p&gt;很多人一上手就用了octopress， 反而弄混了，这里解释下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;github pages, 在gh-pages下都是html文件。&lt;/li&gt;
&lt;li&gt;octopress、pelican、jeklly， 都是用来生成这些html的。&lt;/li&gt;
&lt;li&gt;理论上， 鉴于国内github的速度， 最好的办法是自己弄一台服务器，开一个最简单的http server。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了方便起见， 改写了MakeFile文件， 增加了对百度云的支持， 同时因为一部分文档是不适合泄露的，额外建立一个private的content和output的文件夹， 在MakeFile的html和serve那里增加了对这些的支持。&lt;/p&gt;
&lt;p&gt;申请了一台阿里云的服务器， 准备部署。&lt;/p&gt;
&lt;h2&gt;update&lt;/h2&gt;
&lt;p&gt;申请到阿里云的服务器了， 在服务器上用了个最简单的httpserver:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;nohup&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="n"&gt;SimpleHTTPServer&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在makefile里面配置rsync同步。&lt;/p&gt;</summary></entry><entry><title>实时策略</title><link href="/online%20learning.html" rel="alternate"></link><updated>2013-12-18T00:00:00+08:00</updated><author><name>haoyuan.huhy@gmail.com</name></author><id>tag:,2013-12-18:online learning.html</id><summary type="html">&lt;p&gt;传统的推荐以离线为主， 以预测用户偏好品牌为例，大致分为这几个步骤:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;离线采集计算用户， 品牌等各个维度的特征。&lt;/li&gt;
&lt;li&gt;根据业务目标给出样本集合， 比如比较典型的CTR， 对于给定样本数据， 点击为正例， 不点击为负例。候选集的挑选有时候充满了trick， 尤其在业务的主体流量不是推荐的时候。&lt;/li&gt;
&lt;li&gt;使用模型进行离线训练， 以线性模型居多， 包括LR, pair-wise, list-wise等。在海量情况下， 复杂模型比较罕见。&lt;/li&gt;
&lt;li&gt;根据模型预测获得用户的偏好品牌列表。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相对于直接利用热门或者协同过滤做出的推荐， 这种方式能够获得良好的提升以及更好的泛化能力， 但是面对以下几种情况无能为力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每天有大量新用户拥入。&lt;/li&gt;
&lt;li&gt;用户对品牌的点击在过去没有特征， 看起来似乎是天外飞仙般出现， 但又不是热销。 &lt;/li&gt;
&lt;li&gt;无法实时的对用户的正反馈和负反馈进行算法上的回馈， 尤其是当你发现你X掉了一堆东西， 类似的商品还在源源不断的涌向你的时候。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实时的数据对于推荐系统而言， 是一座新的金矿， 可以为用户进行更准确地推荐， 同时及时响应各种反馈， 提升用户体验。 用户能感受到推荐系统和他的交互， 会更主动积极的贡献自己的行为特点， 从而形成良性循环。&lt;/p&gt;
&lt;p&gt;比较常见的一种做法是实时特征的引入， 训练过程依然在离线完成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;收集实时数据， 做离线训练&lt;/li&gt;
&lt;li&gt;做在线预测&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另一部分采用的是online learning, 利用用户不停的行为反馈（包含显式的和隐式的）， 来调整特征权重。&lt;/p&gt;
&lt;p&gt;现在在考虑一种在线增强学习的方式， 假定我们现在有四种投放策略：a, b, c, d。
对于缺乏历史信息的新用户， 在没有任何信息的情况下， 我们先以轮播的方式在所有的位置投放a, b, c, d四种策略。
随后我们采集相应的反馈信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;点击：显式正反馈&lt;/li&gt;
&lt;li&gt;删除： 显式负反馈&lt;/li&gt;
&lt;li&gt;未点击： 隐式负反馈&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这一过程中快速积累用户对不同策略的敏感程度，同时对离线的预测结果进行纠正。&lt;/p&gt;
&lt;p&gt;由于单独位置对用户的曝光机会有限， 需要以打通的眼光看待所有的投放位置， 将他作为一个整体：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;收集到显式负反馈的策略在全局降分&lt;/li&gt;
&lt;li&gt;收集到显式负反馈的目标在全局过滤&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最轻量级的快速尝试方式是， 对于某部分用户而言， 预估的投放策略可信度已经低于热门了， 或者补全的时候采用相似算法的可信度已经低于热门了， 就可以通过快速切换策略达到在线选择的目的。&lt;/p&gt;
&lt;p&gt;对于实时而言， 不仅仅是算法上的变更， 对系统架构也有巨大的挑战。
    下图是Netflix的实时推荐的架构图：
"&lt;img alt="Netflix架构" src="/images/online系统.jpg" /&gt;"&lt;/p&gt;
&lt;p&gt;系统上， Netflix分为online, near online, offline三个部分， nearline是用户最近的行为数据， 利用流失计算获得一些结果， 产生的结果送到online 用以更新模型。&lt;/p&gt;</summary></entry></feed>